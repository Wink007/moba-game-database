#!/usr/bin/env python3
"""
–ü–∞—Ä—Å–∏–Ω–≥ –ø–∞—Ç—á—ñ–≤ Mobile Legends –∑ Liquipedia
"""

import requests
from bs4 import BeautifulSoup
import json
import re
import time
from datetime import datetime

def fetch_patch_list():
    """–û—Ç—Ä–∏–º—É—î —Å–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö –ø–∞—Ç—á—ñ–≤ –∑ Liquipedia Portal:Patches"""
    print("üìã –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—á—ñ–≤ –∑ Portal:Patches...")
    
    try:
        headers = {
            'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
        }
        response = requests.get('https://liquipedia.net/mobilelegends/Portal:Patches', 
                              headers=headers, timeout=15)
        
        if response.status_code != 200:
            print(f"‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—á—ñ–≤: HTTP {response.status_code}")
            return []
        
        # –í–∏—Ç—è–≥—É—î–º–æ –≤—Å—ñ –ø–æ—Å–∏–ª–∞–Ω–Ω—è –Ω–∞ –ø–∞—Ç—á—ñ
        soup = BeautifulSoup(response.text, 'html.parser')
        patch_links = soup.find_all('a', href=re.compile(r'/mobilelegends/Patch_\d+\.\d+\.\d+'))
        
        # –ó–±–∏—Ä–∞—î–º–æ —É–Ω—ñ–∫–∞–ª—å–Ω—ñ –≤–µ—Ä—Å—ñ—ó
        versions = set()
        for link in patch_links:
            match = re.search(r'Patch_(\d+\.\d+\.\d+)', link.get('href', ''))
            if match:
                versions.add(match.group(1))
        
        # –°–æ—Ä—Ç—É—î–º–æ –≤—ñ–¥ –Ω–∞–π–Ω–æ–≤—ñ—à–∏—Ö –¥–æ –Ω–∞–π—Å—Ç–∞—Ä—ñ—à–∏—Ö
        sorted_versions = sorted(versions, key=lambda v: [int(x) for x in v.split('.')], reverse=True)
        
        patches = []
        for version in sorted_versions:
            patches.append({
                'version': version,
                'name': f'Patch {version}',
                'url': f'https://liquipedia.net/mobilelegends/Patch_{version}'
            })
        
        print(f"‚úÖ –ó–Ω–∞–π–¥–µ–Ω–æ {len(patches)} –ø–∞—Ç—á—ñ–≤ –Ω–∞ Liquipedia\n")
        return patches
        
    except Exception as e:
        print(f"‚ùå –ü–æ–º–∏–ª–∫–∞ –ø—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—ñ —Å–ø–∏—Å–∫—É –ø–∞—Ç—á—ñ–≤: {e}")
        return []


def fetch_patch_details(version):
    """–û—Ç—Ä–∏–º—É—î –¥–µ—Ç–∞–ª—å–Ω—É —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ø–∞—Ç—á"""
    formatted_version = version.replace('.', '.')
    url = f"https://liquipedia.net/mobilelegends/Patch_{formatted_version}"
    
    headers = {
        'User-Agent': 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36'
    }
    
    try:
        response = requests.get(url, headers=headers, timeout=15)
        if response.status_code != 200:
            print(f"  ‚ùå Patch {version}: HTTP {response.status_code}")
            return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        data = {
            'version': version,
            'url': url,
            'release_date': None,
            'highlights': [],
            'hero_changes': {},
            'item_changes': {},
            'system_changes': []
        }
        
        content = soup.find('div', class_='mw-parser-output')
        if not content:
            return None
        
        # –®—É–∫–∞—î–º–æ –¥–∞—Ç—É —Ä–µ–ª—ñ–∑—É –≤ infobox
        infobox = content.find('div', {'data-analytics-infobox-type': 'Patch'})
        if infobox:
            date_cell = infobox.find('div', string=re.compile('Release Date'))
            if date_cell:
                date_div = date_cell.find_next_sibling('div')
                if date_div:
                    date_text = date_div.get_text(strip=True)
                    # 2025-12-18
                    date_match = re.search(r'\d{4}-\d{2}-\d{2}', date_text)
                    if date_match:
                        data['release_date'] = date_match.group(0)
        
        # –í–∏—Ç—è–≥—É—î–º–æ highlights –∑ infobox
        highlights_section = infobox.find('ul') if infobox else None
        if highlights_section:
            for li in highlights_section.find_all('li', recursive=False):
                highlight_text = li.get_text(strip=True)
                if highlight_text:
                    data['highlights'].append(highlight_text)
        
        # –ü—Ä–æ—Å—Ç—ñ—à–∏–π –ø—ñ–¥—Ö—ñ–¥ - –∑–Ω–∞—Ö–æ–¥–∏–º–æ –≤—Å—ñ h3 –≤ content —ñ –ø–∞—Ä—Å–∏–º–æ –Ω–∞—Å—Ç—É–ø–Ω–∏–π div
        all_h3 = content.find_all('h3')
        
        for h3 in all_h3:
            # –ü—Ä–æ–ø—É—Å–∫–∞—î–º–æ h3 —â–æ –Ω–µ –≤ —Å–µ–∫—Ü—ñ—ó Hero Adjustments
            h3_id = h3.get('id', '')
            span = h3.find('span', class_='mw-headline')
            if not span:
                continue
            
            # –®—É–∫–∞—î–º–æ —ñ–º'—è –≥–µ—Ä–æ—è –≤ –Ω–∞—Å—Ç—É–ø–Ω–æ–º—É div
            hero_div = h3.find_next_sibling('div')
            if not hero_div:
                continue
            
            hero_name_elem = hero_div.find('b')
            if not hero_name_elem:
                continue
            
            hero_name = hero_name_elem.get_text(strip=True)
            
            # –Ü–Ω—ñ—Ü—ñ–∞–ª—ñ–∑—É—î–º–æ —Å—Ç—Ä—É–∫—Ç—É—Ä—É –¥–ª—è –≥–µ—Ä–æ—è
            if hero_name not in data['hero_changes']:
                data['hero_changes'][hero_name] = {
                    'summary': '',
                    'changes': []
                }
            
            # –ó–±–∏—Ä–∞—î–º–æ summary –∑ –¥—Ä—É–≥–æ–≥–æ div
            content_divs = hero_div.find_next_siblings('div', limit=3)
            for div in content_divs:
                # –ü–µ—Ä—à–∏–π div –∑ —Ç–µ–∫—Å—Ç–æ–º - summary
                paragraphs = div.find_all('p', recursive=False)
                if paragraphs and not data['hero_changes'][hero_name]['summary']:
                    summary_text = paragraphs[0].get_text(strip=True)
                    if len(summary_text) > 20:
                        data['hero_changes'][hero_name]['summary'] = summary_text
                
                # –ó–±–∏—Ä–∞—î–º–æ –∑–º—ñ–Ω–∏ (—Ç–µ–∫—Å—Ç–∏ –∑ >> –∞–±–æ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ —Ü–∏—Ñ—Ä–∏)
                all_p = div.find_all('p')
                for p in all_p:
                    text = p.get_text(strip=True)
                    # –®—É–∫–∞—î–º–æ –∑–º—ñ–Ω–∏ —Å—Ç–∞—Ç—ñ–≤
                    if '>>' in text or 'Cooldown' in text or 'Damage' in text or 'New Effect' in text:
                        clean_text = re.sub(r'\s+', ' ', text)
                        if clean_text not in data['hero_changes'][hero_name]['changes']:
                            data['hero_changes'][hero_name]['changes'].append(clean_text)
        
        # –ü–∞—Ä—Å–∏–º–æ Equipment Adjustments (items)
        equipment_span = content.find('span', id='Equipment_Adjustments')
        if equipment_span:
            equipment_h3 = equipment_span.find_parent('h3')
            if equipment_h3:
                # –ó–±–∏—Ä–∞—î–º–æ –≤—Å—ñ h4 –ø—ñ—Å–ª—è Equipment Adjustments –¥–æ –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ h2/h3
                current_sibling = equipment_h3.find_next_sibling()
                
                while current_sibling:
                    # –Ø–∫—â–æ h2 –∞–±–æ h3 –±–µ–∑ Equipment - –∑–∞–∫—ñ–Ω—á–∏–ª–∞—Å—å —Å–µ–∫—Ü—ñ—è
                    if current_sibling.name in ['h2', 'h3']:
                        if current_sibling.name == 'h3' or 'Equipment' not in current_sibling.get_text():
                            break
                    
                    # h4 - —Ü–µ –∫–æ–Ω–∫—Ä–µ—Ç–Ω–∏–π –ø—Ä–µ–¥–º–µ—Ç
                    if current_sibling.name == 'h4':
                        item_span = current_sibling.find('span', class_='mw-headline')
                        if item_span:
                            item_name = item_span.get_text(strip=True)
                            
                            if item_name and item_name not in data['item_changes']:
                                data['item_changes'][item_name] = []
                            
                            # –ó–±–∏—Ä–∞—î–º–æ ul/p –ø—ñ—Å–ª—è —Ü—å–æ–≥–æ h4
                            next_elem = current_sibling.find_next_sibling()
                            while next_elem and next_elem.name not in ['h2', 'h3', 'h4']:
                                if next_elem.name == 'ul':
                                    for li in next_elem.find_all('li', recursive=False):
                                        change_text = li.get_text(strip=True)
                                        if change_text:
                                            data['item_changes'][item_name].append(change_text)
                                elif next_elem.name == 'p':
                                    text = next_elem.get_text(strip=True)
                                    if text and '>>' in text:  # –ó–º—ñ–Ω–∞ —Å—Ç–∞—Ç—ñ–≤
                                        data['item_changes'][item_name].append(text)
                                
                                next_elem = next_elem.find_next_sibling()
                                if next_elem and next_elem.name in ['h2', 'h3', 'h4']:
                                    break
                    
                    current_sibling = current_sibling.find_next_sibling()
        
        # –ü–∞—Ä—Å–∏–º–æ System Adjustments
        system_h2 = content.find('span', string=re.compile('System.*Adjustment', re.I))
        if system_h2:
            system_section = system_h2.find_parent('h2')
            if system_section:
                # –ó–±–∏—Ä–∞—î–º–æ ul –ø—ñ—Å–ª—è System Adjustments
                for sibling in system_section.find_next_siblings():
                    if sibling.name == 'h2':
                        break
                    
                    if sibling.name == 'ul':
                        for li in sibling.find_all('li', recursive=False):
                            change_text = li.get_text(strip=True)
                            if change_text:
                                data['system_changes'].append(change_text)
                    elif sibling.name == 'p':
                        change_text = sibling.get_text(strip=True)
                        if change_text and len(change_text) > 20:
                            data['system_changes'].append(change_text)
        
        print(f"  ‚úÖ Patch {version}: OK ({data['release_date']}, {len(data['hero_changes'])} heroes, {len(data['item_changes'])} items)")
        return data
        
    except Exception as e:
        print(f"  ‚ùå Patch {version}: {e}")
        return None


def fetch_latest_patches(limit=10):
    """–û—Ç—Ä–∏–º—É—î –æ—Å—Ç–∞–Ω–Ω—ñ N –ø–∞—Ç—á—ñ–≤"""
    print("üîç –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é –ø–∞—Ç—á—ñ –∑ Liquipedia...\n")
    
    patches = fetch_patch_list()
    
    if not patches:
        print("‚ùå –ù–µ –≤–¥–∞–ª–æ—Å—è –æ—Ç—Ä–∏–º–∞—Ç–∏ —Å–ø–∏—Å–æ–∫ –ø–∞—Ç—á—ñ–≤")
        return []
    
    # –ë–µ—Ä–µ–º–æ —Ç—ñ–ª—å–∫–∏ –ø–µ—Ä—à—ñ limit –ø–∞—Ç—á—ñ–≤ (–≤–∂–µ –≤—ñ–¥—Å–æ—Ä—Ç–æ–≤–∞–Ω—ñ –≤—ñ–¥ –Ω–∞–π–Ω–æ–≤—ñ—à–∏—Ö)
    patches_to_fetch = patches[:limit]
    
    print(f"üì• –ó–∞–≤–∞–Ω—Ç–∞–∂—É—é {len(patches_to_fetch)} –ø–∞—Ç—á—ñ–≤...\n")
    
    detailed_patches = []
    
    for i, patch in enumerate(patches_to_fetch):
        # –ó–∞—Ç—Ä–∏–º–∫–∞ –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏ —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ 429
        if i > 0:
            time.sleep(1.5)  # 1.5 —Å–µ–∫—É–Ω–¥–∏ –º—ñ–∂ –∑–∞–ø–∏—Ç–∞–º–∏
        
        print(f"[{i+1}/{len(patches_to_fetch)}] {patch['version']}...", end=' ')
        details = fetch_patch_details(patch['version'])
        if details:
            detailed_patches.append(details)
        else:
            print(f"‚ö†Ô∏è  –ü—Ä–æ–ø—É—Å–∫–∞—é")
    
    return detailed_patches


if __name__ == "__main__":
    patches = fetch_latest_patches(limit=20)
    
    # –ó–±–µ—Ä—ñ–≥–∞—î–º–æ –≤ JSON
    output_file = 'patches_data.json'
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump(patches, f, indent=2, ensure_ascii=False)
    
    print(f"\n{'='*60}")
    print(f"‚úÖ –ó–∞–≤–µ—Ä—à–µ–Ω–æ! –û–±—Ä–æ–±–ª–µ–Ω–æ {len(patches)} –ø–∞—Ç—á—ñ–≤")
    print(f"üìÑ –î–∞–Ω—ñ –∑–±–µ—Ä–µ–∂–µ–Ω–æ –≤ {output_file}")
    print(f"{'='*60}")
